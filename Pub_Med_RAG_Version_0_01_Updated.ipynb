{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c38cea2",
   "metadata": {},
   "source": [
    "# PubMed RAG Version 0.01\n",
    "\n",
    "This notebook implements a Retrieval-Augmented Generation (RAG) pipeline for PubMed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zsquK-JLgEak"
   },
   "outputs": [],
   "source": [
    "# Code implementation\n",
    "! pip install langchain_community tiktoken langchain-openai langchainhub chromadb langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c191b1",
   "metadata": {},
   "source": [
    "## 1. Importing Necessary Libraries\n",
    "\n",
    "In this section, we import the required Python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JKpllfXHgPx0"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "from google.colab import userdata\n",
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "secret_langchain_key_value = userdata.get('LANGCHAIN_API_KEY')\n",
    "secret_openai_key_value = userdata.get('OPENAI_API_KEY')\n",
    "os.environ['LANGCHAIN_API_KEY'] = secret_langchain_key_value\n",
    "os.environ['OPENAI_API_KEY'] = secret_openai_key_value\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bc7559",
   "metadata": {},
   "source": [
    "## 2. Loading and Preprocessing Data\n",
    "\n",
    "This section loads and preprocesses the PubMed dataset for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gRLAVC4MhXiY"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "!pip install datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Enable streaming to avoid full dataset download\n",
    "dataset = load_dataset(\"MedRAG/pubmed\", split=\"train\", streaming=True)\n",
    "\n",
    "# Take only the first 100 samples (or any number)\n",
    "subset = dataset.skip(500).take(100)  # Skip first 500, then take 100\n",
    "\n",
    "# Convert to list for easy access (optional)\n",
    "subset_list = list(subset)\n",
    "\n",
    "# Print first sample\n",
    "print(subset_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225c938a",
   "metadata": {},
   "source": [
    "## 3. Embedding Generation\n",
    "\n",
    "We generate embeddings for the textual data to facilitate similarity search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tG3va36ohepX"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(subset_list)\n",
    "# store to csv\n",
    "df.to_csv('pubmed_subset.csv', index=False)\n",
    "\n",
    "# download the csv\n",
    "from google.colab import files\n",
    "files.download('pubmed_subset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2827850d",
   "metadata": {},
   "source": [
    "## 4. Retrieval Mechanism\n",
    "\n",
    "Here, we implement the retrieval process using FAISS or another vector search method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zxmhUugchhDu"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "documents = [\n",
    "    {\n",
    "        \"id\": item[\"id\"],\n",
    "        \"title\": item[\"title\"],\n",
    "        \"content\": item[\"content\"],\n",
    "        \"contents\": item[\"contents\"],\n",
    "        \"PMID\": item[\"PMID\"]\n",
    "    }\n",
    "    for item in subset_list\n",
    "]\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Initialize text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "\n",
    "# Prepare chunks with metadata\n",
    "chroma_docs = []\n",
    "\n",
    "for doc in documents:\n",
    "    chunks = text_splitter.split_text(doc[\"content\"])  # Split document into smaller chunks\n",
    "    for chunk in chunks:\n",
    "        chroma_docs.append({\"text\": chunk, \"metadata\": {\"id\": doc[\"id\"], \"title\": doc[\"title\"], \"PMID\": doc[\"PMID\"]}})\n",
    "\n",
    "# Verify results\n",
    "print(f\"Total Chunks: {len(chroma_docs)}\")\n",
    "print(f\"Sample Chunk: {chroma_docs[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d70dd4",
   "metadata": {},
   "source": [
    "## 5. RAG Model Implementation\n",
    "\n",
    "This section integrates the retrieved information with a language model to generate responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E-WEoHFdhi_D"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# Initialize ChromaDB\n",
    "vectorstore = Chroma.from_texts(\n",
    "    texts=[doc[\"text\"] for doc in chroma_docs],\n",
    "    metadatas=[doc[\"metadata\"] for doc in chroma_docs],\n",
    "    embedding=OpenAIEmbeddings()\n",
    ")\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6897cac7",
   "metadata": {},
   "source": [
    "## 6. Evaluation and Testing\n",
    "\n",
    "We evaluate the system's performance and test the retrieval-augmented generation pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2C_8DorUhkpI"
   },
   "outputs": [],
   "source": [
    "# Code implementation\n",
    "queries = [\n",
    "    \"Lysosomal hydrolases of the epidermis\",\n",
    "    \"Micellar solubilization of fatty acids\",\n",
    "    \"Influence of phospholipolysis on solubility\",\n",
    "    \"Purification and characterization of folate binding proteins\",\n",
    "    \"Effects of anaerobic bacteria in wound healing\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"Query: {query}\\n\")\n",
    "    results = retriever.get_relevant_documents(query)\n",
    "\n",
    "    for r in results:\n",
    "        print(f\"Title: {r.metadata['title']}\\nPMID: {r.metadata['PMID']}\\nText: {r.page_content[:500]}\\n---\")\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
